---
- name: Create and configure libvirt VMs
  hosts: libvirt_hosts
  become: true
  gather_facts: true
  
  vars:
    vm_config: "{{ hostvars[target_vm] }}"
    
  tasks:
    - name: Install required system packages
      package:
        name:
          # Libvirt and virtualization
          - libvirt-daemon-system
          - libvirt-clients
          - libvirt-dev
          # QEMU/KVM
          - qemu-kvm
          - qemu-utils
          - qemu-system-x86
          # VM management tools
          - virtinst
          - virt-manager
          - virt-viewer
          # Networking
          - bridge-utils
          - dnsmasq
          # Cloud-init ISO creation
          - genisoimage
          # Python development headers (needed for libvirt-python and lxml)
          - python3-dev
          - gcc
          - pkg-config
          # XML libraries (needed for lxml)
          - libxml2-dev
          - libxslt1-dev
          - zlib1g-dev
        state: present
      tags: setup

    - name: Install Python dependencies for Ansible libvirt modules via uv pip
      command: uv pip install 'libvirt-python>=9.0.0' 'lxml>=4.9.0'
      become: false
      delegate_to: localhost
      tags: setup
      register: uv_pip_result
      changed_when: "'Successfully installed' in uv_pip_result.stdout"

    - name: Ensure libvirtd service is running
      systemd:
        name: libvirtd
        state: started
        enabled: true
      tags: setup

    - name: Add current user to libvirt group
      user:
        name: "{{ ansible_user_id }}"
        groups: libvirt
        append: true
      tags: setup

    - name: Create base images directory
      file:
        path: "{{ base_image_path }}"
        state: directory
        mode: '0755'
      tags: setup

    - name: Create secrets directory
      file:
        path: "../secrets"
        state: directory
        mode: '0755'
      delegate_to: localhost
      become: false
      tags: setup

    - name: Check if SSH key already exists
      stat:
        path: "{{ vm_ssh_key_path }}"
      delegate_to: localhost
      become: false
      register: ssh_key_stat
      tags: setup

    - name: Generate ed25519 SSH key for VMs
      command: >
        ssh-keygen -t ed25519 
        -f {{ vm_ssh_key_path }} 
        -N "" 
        -C "libvirt-vms-key"
      delegate_to: localhost
      become: false
      when: not ssh_key_stat.stat.exists
      tags: setup

    - name: Display SSH key information
      debug:
        msg: |
          {% if ssh_key_stat.stat.exists %}
          ✅ SSH key already exists: {{ vm_ssh_key_path }}
          {% else %}
          ✅ Generated new SSH key: {{ vm_ssh_key_path }}
          {% endif %}
          Public key: {{ vm_ssh_public_key_path }}
      delegate_to: localhost
      become: false
      tags: setup

    - name: Check if static DHCP network needs to be configured
      community.libvirt.virt_net:
        command: info
        name: default
        uri: "{{ libvirt_uri | default('qemu:///system') }}"
      register: network_info
      tags: network

    - name: Setup static DHCP reservations for consistent IP assignments
      block:
        - name: Stop default network
          community.libvirt.virt_net:
            command: destroy
            name: default
            uri: "{{ libvirt_uri | default('qemu:///system') }}"
          ignore_errors: true

        - name: Undefine existing default network
          community.libvirt.virt_net:
            command: undefine
            name: default
            uri: "{{ libvirt_uri | default('qemu:///system') }}"

        - name: Define updated default network with static DHCP reservations
          community.libvirt.virt_net:
            command: define
            name: default
            xml: "{{ lookup('file', 'static-network.xml') }}"
            uri: "{{ libvirt_uri | default('qemu:///system') }}"

        - name: Start default network with static reservations
          community.libvirt.virt_net:
            command: start
            name: default
            uri: "{{ libvirt_uri | default('qemu:///system') }}"

        - name: Set default network to autostart
          community.libvirt.virt_net:
            autostart: true
            name: default
            uri: "{{ libvirt_uri | default('qemu:///system') }}"

        - name: Display static DHCP configuration
          debug:
            msg: |
              ✅ Static DHCP reservations configured:
              - ubuntu-dev:       192.168.122.10 (MAC: 52:54:00:12:34:10)
              - ubuntu-gpu:       192.168.122.11 (MAC: 52:54:00:12:34:11)
              - DHCP range for other VMs: 192.168.122.100-200
      when: 
        - network_info is defined
      tags: network

    - name: Check if source image exists
      stat:
        path: "{{ source_image_path }}"
      register: source_image_stat
      tags: image

    - name: Copy source image to libvirt images directory
      copy:
        src: "{{ source_image_path }}"
        dest: "{{ base_image_path }}/{{ base_image_name }}"
        mode: '0644'
        remote_src: true
      when: source_image_stat.stat.exists
      tags: image

    - name: Create VM disk from base image
      copy:
        src: "{{ base_image_path }}/{{ base_image_name }}"
        dest: "{{ base_image_path }}/{{ vm_config.vm_name }}.qcow2"
        mode: '0644'
        remote_src: true
      tags: disk

    - name: Get current disk info
      command: qemu-img info --output json {{ base_image_path }}/{{ vm_config.vm_name }}.qcow2
      register: disk_info
      tags: disk

    - name: Parse disk info
      set_fact:
        current_virtual_size: "{{ (disk_info.stdout | from_json)['virtual-size'] }}"
        target_size_bytes: "{{ vm_config.vm_disk_size | default(default_vm_disk_size) | regex_replace('G$', '') | int * 1024 * 1024 * 1024 }}"
      tags: disk

    - name: Resize VM disk (only if target is larger)
      command: >
        qemu-img resize 
        {{ base_image_path }}/{{ vm_config.vm_name }}.qcow2 
        {{ vm_config.vm_disk_size | default(default_vm_disk_size) }}
      when: target_size_bytes | int > current_virtual_size | int
      tags: disk

    - name: Display disk size info
      debug:
        msg: |
          Current virtual size: {{ (current_virtual_size | int / 1024 / 1024 / 1024) | round(1) }}G
          Target size: {{ vm_config.vm_disk_size | default(default_vm_disk_size) }}
          {% if target_size_bytes | int > current_virtual_size | int %}
          ✅ Disk will be resized to {{ vm_config.vm_disk_size | default(default_vm_disk_size) }}
          {% else %}
          ℹ️  Disk size unchanged (target not larger than current)
          {% endif %}
      tags: disk

    - name: Create cloud-init config directory for VM
      file:
        path: "/tmp/cloud-init-{{ vm_config.vm_name }}"
        state: directory
        mode: '0755'
      tags: cloud-init

    - name: Read SSH public key content
      slurp:
        src: "{{ vm_ssh_public_key_path }}"
      register: ssh_public_key_content
      delegate_to: localhost
      become: false
      tags: cloud-init

    - name: Set SSH key content as a separate variable
      set_fact:
        vm_ssh_key: "{{ ssh_public_key_content.content | b64decode | trim }}"
      tags: cloud-init

    - name: Generate cloud-init user-data for VM with static IP
      template:
        src: user-data.j2
        dest: "/tmp/cloud-init-{{ vm_config.vm_name }}/user-data"
        mode: '0644'
      tags: cloud-init

    - name: Generate cloud-init meta-data for VM
      template:
        src: meta-data.j2
        dest: "/tmp/cloud-init-{{ vm_config.vm_name }}/meta-data"
        mode: '0644'
      tags: cloud-init

    - name: Create cloud-init ISO for VM
      command: >
        genisoimage -output /var/lib/libvirt/images/{{ vm_config.vm_name }}-cloud-init.iso 
        -volid cidata -joliet -r 
        /tmp/cloud-init-{{ vm_config.vm_name }}/user-data 
        /tmp/cloud-init-{{ vm_config.vm_name }}/meta-data
      tags: cloud-init

    - name: Generate VM XML configuration
      template:
        src: vm-config.xml.j2
        dest: "/tmp/{{ vm_config.vm_name }}.xml"
        mode: '0644'
      tags: xml

    - name: Define VM
      community.libvirt.virt:
        command: define
        xml: "{{ lookup('file', '/tmp/' + vm_config.vm_name + '.xml') }}"
        uri: "{{ libvirt_uri | default('qemu:///system') }}"
      tags: define

    - name: Set VM autostart
      community.libvirt.virt:
        name: "{{ vm_config.vm_name }}"
        autostart: "{{ vm_config.vm_autostart | default(false) }}"
        uri: "{{ libvirt_uri | default('qemu:///system') }}"
      tags: autostart

    - name: Validate GPU passthrough setup (if GPU VM)
      block:
        - name: Check if GPU device is bound to vfio-pci
          shell: |
            if [ -d "/sys/bus/pci/devices/{{ vm_config.gpu_device_id }}/driver" ]; then
              driver=$(basename $(readlink /sys/bus/pci/devices/{{ vm_config.gpu_device_id }}/driver))
              echo "$driver"
            else
              echo "no_driver"
            fi
          register: gpu_driver
          changed_when: false

        - name: Check IOMMU group viability
          shell: |
            iommu_group=$(basename $(readlink /sys/bus/pci/devices/{{ vm_config.gpu_device_id }}/iommu_group))
            echo "IOMMU_GROUP:$iommu_group"
            all_vfio=true
            for device in /sys/kernel/iommu_groups/$iommu_group/devices/*; do
              device_id=$(basename $device)
              if [ -d "$device/driver" ]; then
                driver=$(basename $(readlink $device/driver))
              else
                driver="no_driver"
              fi
              echo "DEVICE:$device_id:$driver"
              if [ "$driver" != "vfio-pci" ]; then
                all_vfio=false
              fi
            done
            if [ "$all_vfio" = true ]; then
              echo "STATUS:OK"
            else
              echo "STATUS:FAIL"
            fi
          register: iommu_group_info
          changed_when: false

        - name: Parse IOMMU group information
          set_fact:
            iommu_group_number: "{{ iommu_group_info.stdout_lines | select('match', '^IOMMU_GROUP:') | first | regex_replace('^IOMMU_GROUP:', '') }}"
            iommu_devices: "{{ iommu_group_info.stdout_lines | select('match', '^DEVICE:') | map('regex_replace', '^DEVICE:', '') | list }}"
            iommu_status: "{{ iommu_group_info.stdout_lines | select('match', '^STATUS:') | first | regex_replace('^STATUS:', '') }}"

        - name: Display IOMMU group information
          debug:
            msg: |
              IOMMU Group {{ iommu_group_number }} contains:
              {% for device_info in iommu_devices %}
              {% set parts = device_info.split(':') %}
              - {{ parts[0] }} -> {{ parts[1] }}
              {% endfor %}

        - name: Fail if IOMMU group is not viable
          fail:
            msg: |
              ❌ GPU passthrough is not properly configured!

              GPU Device: {{ vm_config.gpu_device_id }}
              IOMMU Group: {{ iommu_group_number }}

              All devices in IOMMU Group {{ iommu_group_number }} must be bound to vfio-pci:
              {% for device_info in iommu_devices %}
              {% set parts = device_info.split(':') %}
              - {{ parts[0] }}: {{ parts[1] }} {% if parts[1] != 'vfio-pci' %}❌{% else %}✅{% endif %}
              {% endfor %}

              To fix this issue, you must bind ALL devices in the IOMMU group to vfio-pci:

              {% for device_info in iommu_devices %}
              {% set parts = device_info.split(':') %}
              {% if parts[1] != 'vfio-pci' %}
              # Unbind {{ parts[0] }} from {{ parts[1] }}
              echo "{{ parts[0] }}" | sudo tee /sys/bus/pci/drivers/{{ parts[1] }}/unbind

              # Bind {{ parts[0] }} to vfio-pci
              echo "vfio-pci" | sudo tee /sys/bus/pci/devices/{{ parts[0] }}/driver_override
              echo "{{ parts[0] }}" | sudo tee /sys/bus/pci/drivers/vfio-pci/bind
              {% endif %}
              {% endfor %}

              Or see ansible/NVIDIA-GPU-PASSTHROUGH-GUIDE.md for detailed setup steps.
          when: iommu_status != "OK"
      when: vm_config.gpu_passthrough | default(false) | bool
      tags: [gpu-validation, start]

    - name: Start VM
      community.libvirt.virt:
        name: "{{ vm_config.vm_name }}"
        state: running
        uri: "{{ libvirt_uri | default('qemu:///system') }}"
      tags: start

    - name: Get VM IP address
      community.libvirt.virt:
        command: list_vms
        uri: "{{ libvirt_uri | default('qemu:///system') }}"
      register: vm_list
      tags: info

    - name: Display VM information
      debug:
        msg: |
          VM '{{ vm_config.vm_name }}' has been created and started.
          Connect via VNC: virt-viewer {{ vm_config.vm_name }}
          Or use SSH once the VM is fully booted: ssh {{ vm_ssh_user }}@<VM_IP>
      tags: info
